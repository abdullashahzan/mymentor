import os
import numpy as np
import torchvision.datasets.mnist as mnist

# Define the datasets directory
datasets_dir = './datasets'
if not os.path.exists(datasets_dir):
    os.makedirs(datasets_dir)  # Create the datasets directory if it doesn't exist
# URL of the MNIST dataset zip file
mnist_url = 'https://labfiles-singapore.obs.ap-southeast-3.myhuaweicloud.com/modelarts/MNIST_data.zip'
zip_file_path = os.path.join(datasets_dir, 'MNIST_data.zip')
# Download the MNIST_data.zip file using wget
!wget {mnist_url} -O {zip_file_path}
# Unzip the downloaded file into the datasets directory
!unzip {zip_file_path} -d {datasets_dir}

# Read all training samples.
train_data = mnist.read_image_file(os.path.join(datasets_dir, 'MNIST_data/raw/train-images-idx3-ubyte')).numpy().astype(np.uint8)
train_label = mnist.read_label_file(os.path.join(datasets_dir, 'MNIST_data/raw/train-labels-idx1-ubyte')).numpy().astype(np.uint8)
# Read all test samples.
test_data = mnist.read_image_file(os.path.join(datasets_dir, 'MNIST_data/raw/t10k-images-idx3-ubyte')).numpy().astype(np.uint8)
test_label = mnist.read_label_file(os.path.join(datasets_dir, 'MNIST_data/raw/t10k-labels-idx1-ubyte')).numpy().astype(np.uint8)

train_zeros = train_data[train_label == 0]
train_ones = train_data[train_label == 1]
test_zeros = test_data[test_label == 0]
test_ones = test_data[test_label == 1]

print('Digit 0: Training set scale: ', len(train_zeros), ', Test set scale: ', len(test_zeros))
print('Digit 1: Training set scale: ', len(train_ones), ', Test set scale: ', len(test_ones))

Digit 0: Training set scale: 5923 , Test set scale: 980
Digit 1: Training set scale: 6742 , Test set scale: 1135

train_x = np.vstack((train_zeros, train_ones)) # Summarize the samples of digits 0 and 1. <strong>np.vstack</strong> indicates stacking two arrays vertically.
train_y = np.array([0] * len(train_zeros) + [1] * len(train_ones)).astype(np.uint8)

test_x = np.vstack((test_zeros, test_ones))  # Summarize the samples of digits 0 and 1. <strong>np.vstack</strong> indicates stacking two arrays vertically.
test_y = np.array([0] * len(test_zeros) + [1] * len(test_ones)).astype(np.uint8)

train_x = train_x.reshape(-1, 28*28)  # Reshape each sample into a row vector to facilitate calculation.
train_y = train_y.reshape(-1, 1)

test_x = test_x.reshape(-1, 28*28)  # Reshape each sample into a row vector to facilitate calculation.
test_y = test_y.reshape(-1, 1)

print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)

train_data = np.hstack((train_x, train_y))  # <strong>np.hstack</strong> indicates stacking two arrays horizontally.
test_data = np.hstack((test_x, test_y))  # <strong>np.hstack</strong> indicates stacking two arrays horizontally.
np.random.seed(0)
np.random.shuffle(train_data)  # Shuffle the rows of the <strong>train_data</strong> array.
np.random.shuffle(test_data)  # Shuffle the rows of the <strong>test_data</strong> array.
train_x = train_data[:, :-1]  # Reshape <strong>train_x</strong> and <strong>train_y</strong>.
train_y = train_data[:, -1].reshape(-1, 1)
test_x = test_data[:, :-1]  # Reshape <strong>train_x</strong> and <strong>train_y</strong>.
test_y = test_data[:, -1].reshape(-1, 1)

from PIL import Image
batch_size = 10  # Check 10 samples.
print(train_y.flatten()[:batch_size].tolist())
batch_img = train_x[0].reshape(28, 28)
for i in range(1, batch_size):
    batch_img = np.hstack((batch_img, train_x[i].reshape(28, 28)))  # Stack a batch of images horizontally to facilitate display in the next step.
Image.fromarray(batch_img)

train_x = train_x.astype(np.float) / 255.0
train_y = train_y.astype(np.float)

test_x = test_x.astype(np.float) / 255.0
test_y = test_y.astype(np.float)

def load_data_zeros_ones(datasets_dir):
    import os
    import numpy as np
    import torchvision.datasets.mnist as mnist

    # Define the datasets directory
    datasets_dir = './datasets'
    if not os.path.exists(datasets_dir):
        os.makedirs(datasets_dir)  # Create the datasets directory if it doesn't exist
    # URL of the MNIST dataset zip file
    mnist_url = 'https://labfiles-singapore.obs.ap-southeast-3.myhuaweicloud.com/modelarts/MNIST_data.zip'
    zip_file_path = os.path.join(datasets_dir, 'MNIST_data.zip')
    # Download the MNIST_data.zip file using wget
    !wget {mnist_url} -O {zip_file_path}
    # Unzip the downloaded file into the datasets directory
    !unzip {zip_file_path} -d {datasets_dir}
    
    # Read all training samples.
    train_data = mnist.read_image_file(os.path.join(datasets_dir, 'MNIST_data/raw/train-images-idx3-ubyte')).numpy().astype(np.uint8)
    train_label = mnist.read_label_file(os.path.join(datasets_dir, 'MNIST_data/raw/train-labels-idx1-ubyte')).numpy().astype(np.uint8)
    # Read all test samples.
    test_data = mnist.read_image_file(os.path.join(datasets_dir, 'MNIST_data/raw/t10k-images-idx3-ubyte')).numpy().astype(np.uint8)
    test_label = mnist.read_label_file(os.path.join(datasets_dir, 'MNIST_data/raw/t10k-labels-idx1-ubyte')).numpy().astype(np.uint8)

    train_zeros = train_data[train_label == 0]
    train_ones = train_data[train_label == 1]
    test_zeros = test_data[test_label == 0]
    test_ones = test_data[test_label == 1]

    print('Digit 0: Training set scale: ', len(train_zeros), ', Test set scale: ', len(test_zeros))
    print('Digit 1: Training set scale: ', len(train_ones), ', Test set scale: ', len(test_ones))
    
    train_x = np.vstack((train_zeros, train_ones)) # Summarize the samples of digits 0 and 1. <strong>np.vstack</strong> indicates stacking two arrays vertically.
    train_y = np.array([0] * len(train_zeros) + [1] * len(train_ones)).astype(np.uint8)

    test_x = np.vstack((test_zeros, test_ones))  # Summarize the samples of digits 0 and 1. <strong>np.vstack</strong> indicates stacking two arrays vertically.
    test_y = np.array([0] * len(test_zeros) + [1] * len(test_ones)).astype(np.uint8)
    
    train_x = train_x.reshape(-1, 28*28)  # Reshape each sample into a row vector to facilitate calculation.
    train_y = train_y.reshape(-1, 1)

    test_x = test_x.reshape(-1, 28*28)  # Reshape each sample into a row vector to facilitate calculation.
    test_y = test_y.reshape(-1, 1)
    
    train_data = np.hstack((train_x, train_y))  # <strong>np.hstack</strong> indicates stacking two arrays horizontally.
    test_data = np.hstack((test_x, test_y))  # <strong>np.hstack</strong> indicates stacking two arrays horizontally.
    np.random.seed(0)
    np.random.shuffle(train_data)  # Shuffle the rows of the <strong>train_data</strong> array.
    np.random.shuffle(test_data)  # Shuffle the rows of the <strong>test_data</strong> array.
    train_x = train_data[:, :-1]  # Reshape <strong>train_x</strong> and <strong>train_y</strong>.
    train_y = train_data[:, -1].reshape(-1, 1)
    test_x = test_data[:, :-1]  # Reshape <strong>train_x</strong> and <strong>train_y</strong>.
    test_y = test_data[:, -1].reshape(-1, 1)
    
    train_x = train_x.astype(np.float) / 255.0
    train_y = train_y.astype(np.float)

    test_x = test_x.astype(np.float) / 255.0
    test_y = test_y.astype(np.float)

    return train_x, train_y, test_x, test_y

np.random.seed(0)

class Network(object):
    def __init__(self, num_of_weights):
        self.w = np.random.randn(num_of_weights, 1)  # Use <strong>np.random.randn</strong> to randomly generate a column vector <strong>num_of_weights*1</strong>. The vector is the weight W.
        self.b = 0.
    
    def forward(self, x):  # Implement the weighted sum function unit and nonlinear function unit by defining a calculation process.
        z = np.dot(x, self.w) + self.b  # Weighted sum
        pred_y = 1.0 / (1.0 + np.exp(-z))  # Nonlinear function sigmoid
        return pred_y

net1 = Network(28*28)
sample = train_x[0]
true_y = train_y[0]
pred_y_1 = net1.forward(sample)
print('true_y:', true_y, 'pred_y:', pred_y_1)

net2 = Network(28*28)
sample = train_x[0]
true_y = train_y[0]
pred_y_2 = net2.forward(sample)
print('true_y:', true_y, 'pred_y:', pred_y_2)

loss1 = (pred_y_1 - true_y)**2
loss2 = (pred_y_2 - true_y)**2
print('loss1:', loss1, 'loss2:', loss2)

class Network(object):
    def __init__(self, num_of_weights):
        np.random.seed(0)
        self.w = np.random.randn(num_of_weights, 1)  # Use <strong>np.random.randn</strong> to randomly generate a column vector <strong>num_of_weights*1</strong>. The vector is the weight W.
        self.b = 0.
    
    def forward(self, x):  # Implement the weighted sum function unit and nonlinear function unit by defining a calculation process.
        z = np.dot(x, self.w) + self.b  # Weighted sum
        pred_y = 1.0 / (1.0 + np.exp(-z))  # Nonlinear function sigmoid
        return pred_y

    def loss_fun(self, pred_y, true_y):
        """
        pred_y: a column vector composed of the predicted values of a batch of samples by the network.
        true_y: true labels of a batch of samples.
        """
        error = pred_y - true_y
        num_samples = error.shape[0]
        cost = error * error
        cost = np.sum(cost) / num_samples
        return cost

net3 = Network(28*28)
sample = train_x[0:10]
true_y = train_y[0:10]
pred_y = net3.forward(sample)
print('loss:', net3.loss_fun(pred_y, true_y))

class Network(object):
    def __init__(self, num_of_weights):
        np.random.seed(0)
        self.w = np.random.randn(num_of_weights, 1)  # Use <strong>np.random.randn</strong> to randomly generate a column vector <strong>num_of_weights*1</strong>. The vector is the weight W.
        self.b = 0.
    
    def forward(self, x):  # Implement the weighted sum function unit and nonlinear function unit by defining a calculation process.
        z = np.dot(x, self.w) + self.b  # Weighted sum
        pred_y = 1.0 / (1.0 + np.exp(-z))  # Nonlinear function sigmoid
        return pred_y

    def loss_fun(self, pred_y, true_y):
        """
        pred_y: a column vector composed of the predicted values of a batch of samples by the network.
        true_y: true labels of a batch of samples.
        """
        error = pred_y - true_y
        num_samples = error.shape[0]
        cost = error * error
        cost = np.sum(cost) / num_samples
        return cost
    
    def evaluate(self, pred_y, true_y, threshold=0.5):
        pred_y[pred_y < threshold] = 0  # If the predicted value is less than 0.5, the digit is classified as 0.
        pred_y[pred_y >= threshold] = 1

        acc = (pred_y == true_y).float().mean()
        return acc

class Network(object):
    def __init__(self, num_of_weights):
        np.random.seed(0)
        self.w = np.random.randn(num_of_weights, 1)  # Use <strong>np.random.randn</strong> to randomly generate a column vector <strong>num_of_weights*1</strong>. The vector is the weight W.
        self.b = 0.
    
    def forward(self, x):  # Implement the weighted sum function unit and nonlinear function unit by defining a calculation process.
        z = np.dot(x, self.w) + self.b  # Weighted sum
        pred_y = 1.0 / (1.0 + np.exp(-z))  # Nonlinear function sigmoid
        return pred_y

    def loss_fun(self, pred_y, true_y):
        """
        pred_y: a column vector composed of the predicted values of a batch of samples by the network.
        true_y: true labels of a batch of samples.
        """
        error = pred_y - true_y
        num_samples = error.shape[0]
        cost = error * error
        cost = np.sum(cost) / num_samples
        return cost
    
    def evaluate(self, pred_y, true_y, threshold=0.5):
        pred_y[pred_y < threshold] = 0  # If the predicted value is less than 0.5, the digit is classified as 0.
        pred_y[pred_y >= threshold] = 1

        acc = (pred_y == true_y).float().mean()
        return acc
    
    def gradient(self, x, y, pred_y):
        gradient_w = (pred_y-y)*pred_y*(1-pred_y)*x
        gradient_w = np.mean(gradient_w, axis=0)
        gradient_w = gradient_w[:, np.newaxis]
        gradient_b = (pred_y - y)*pred_y*(1-pred_y)
        gradient_b = np.mean(gradient_b)        
        return gradient_w, gradient_b
    
    def update(self, gradient_w, gradient_b, eta = 0.01):
        self.w = self.w - eta * gradient_w
        self.b = self.b - eta * gradient_b

class Network(object):
    def __init__(self, num_of_weights):
        np.random.seed(0)
        self.w = np.random.randn(num_of_weights, 1)  # Use <strong>np.random.randn</strong> to randomly generate a column vector <strong>num_of_weights*1</strong>. The vector is the weight W.
        self.b = 0.
    
    def forward(self, x):  # Implement the weighted sum function unit and nonlinear function unit by defining a calculation process.
        z = np.dot(x, self.w) + self.b  # Weighted sum
        pred_y = 1.0 / (1.0 + np.exp(-z))  # Nonlinear function sigmoid
        return pred_y

    def loss_fun(self, pred_y, true_y):
        """
        pred_y: a column vector composed of the predicted values of a batch of samples by the network.
        true_y: true labels of a batch of samples.
        """
        error = pred_y - true_y
        num_samples = error.shape[0]
        cost = error * error
        cost = np.sum(cost) / num_samples
        return cost
    
    def evaluate(self, pred_y, true_y, threshold=0.5):
        pred_y[pred_y < threshold] = 0  # If the predicted value is less than 0.5, the digit is classified as 0.
        pred_y[pred_y >= threshold] = 1

        acc = np.mean((pred_y == true_y).astype(np.float))
        return acc
    
    def gradient(self, x, y, pred_y):
        gradient_w = (pred_y-y)*pred_y*(1-pred_y)*x
        gradient_w = np.mean(gradient_w, axis=0)
        gradient_w = gradient_w[:, np.newaxis]
        gradient_b = (pred_y - y)*pred_y*(1-pred_y)
        gradient_b = np.mean(gradient_b)        
        return gradient_w, gradient_b
    
    def update(self, gradient_w, gradient_b, lr = 0.01):
        self.w = self.w - lr * gradient_w
        self.b = self.b - lr * gradient_b
    
    def train(self, train_x, train_y, test_x, test_y, max_epochs=100, lr=0.01):
        train_losses = []
        test_losses = []
        train_accs = []
        test_accs = []
        for epoch in range(1, max_epochs + 1):
            pred_y_train = self.forward(train_x)
            gradient_w, gradient_b = self.gradient(train_x, train_y, pred_y_train)
            self.update(gradient_w, gradient_b, lr)              
            if (epoch == 1) or (epoch % 200 == 0):
                pred_y_test = self.forward(test_x)
                train_loss = self.loss_fun(pred_y_train, train_y)
                test_loss = self.loss_fun(pred_y_test, test_y)
                train_acc = self.evaluate(pred_y_train, train_y)
                test_acc = self.evaluate(pred_y_test, test_y)
                print('epoch: %d, train_loss: %.4f, test_loss: %.4f, train_acc: %.4f, test_acc: %.4f' % (epoch, train_loss, test_loss, train_acc, test_acc))
                train_losses.append(train_loss)
                test_losses.append(test_loss)
                train_accs.append(train_acc)
                test_accs.append(test_acc)
        return train_losses, test_losses, train_accs, test_accs

import time
start_time = time.time()
# Create a network.
net = Network(28*28)
max_epochs = 3000
# Start training.
train_losses, test_losses, train_accs, test_accs = net.train(train_x, train_y, test_x, test_y, max_epochs=max_epochs, lr=0.01)
print('cost time: %.1f s' % (time.time() - start_time))

import matplotlib.pyplot as plt
%matplotlib inline

# Plot the trends of these indicators.
plot_x = np.arange(0, max_epochs+1, 200)
plot_y_1 = np.array(train_losses)
plot_y_2 = np.array(test_losses)
plot_y_3 = np.array(train_accs)
plot_y_4 = np.array(test_accs)
plt.plot(plot_x, plot_y_1)
plt.plot(plot_x, plot_y_2)
plt.plot(plot_x, plot_y_3)
plt.plot(plot_x, plot_y_4)
plt.show()

