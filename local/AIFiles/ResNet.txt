# Importing the necessary libraries for deep learning and computer vision tasks.
import torch
import torch.nn as nn  # Neural network modules
import torch.optim as optim  # Optimizers for training
import torchvision  # Library for vision-related tasks
import torchvision.transforms as transforms  # For data preprocessing
from torch.utils.data import DataLoader  # For batching and loading datasets

# Defining the BasicBlock used in ResNet. This block consists of two convolutional layers,
# batch normalization, ReLU activations, and a shortcut (skip connection) for residual learning.

class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock, self).__init__()
        # First convolutional layer with a 3x3 kernel, stride and padding set to 1.
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)  # Batch normalization after the first convolution
        self.relu = nn.ReLU(inplace=True)  # ReLU activation
        # Second convolutional layer with a 3x3 kernel, no stride.
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)  # Batch normalization after the second convolution

        # The shortcut connection will adjust dimensions if the input and output channels are different.
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)  # Apply batch normalization to the shortcut
            )

    def forward(self, x):
        # Pass through the first convolutional layer, followed by batch normalization and ReLU activation
        out = self.relu(self.bn1(self.conv1(x)))
        # Pass through the second convolutional layer, followed by batch normalization
        out = self.bn2(self.conv2(out))
        # Add the shortcut connection (skip connection) to the output
        out += self.shortcut(x)
        out = self.relu(out)  # Final ReLU activation
        return out

# Defining the ResNet architecture, consisting of an initial convolutional layer,
# followed by four layers of residual blocks. The final fully connected layer 
# outputs class predictions.

class ResNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ResNet, self).__init__()
        # Initial convolutional layer with a kernel size of 3x3, stride 1, and padding 1
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)  # Batch normalization
        self.relu = nn.ReLU(inplace=True)  # ReLU activation

        # Create multiple layers of residual blocks using the _make_layer method
        self.layer1 = self._make_layer(64, 64, 2, stride=1)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        self.layer4 = self._make_layer(256, 512, 2, stride=2)

        # Global average pooling to reduce the feature map to a single value per channel
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        # Fully connected layer that outputs predictions for the classes
        self.fc = nn.Linear(512, num_classes)

    # Helper function to create each layer of residual blocks
    def _make_layer(self, in_channels, out_channels, num_blocks, stride):
        layers = []
        layers.append(BasicBlock(in_channels, out_channels, stride))  # First block with stride for downsampling
        for _ in range(1, num_blocks):  # Subsequent blocks without stride
            layers.append(BasicBlock(out_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        # Initial convolutional layer followed by batch normalization and ReLU
        x = self.relu(self.bn1(self.conv1(x)))
        # Pass through each layer of residual blocks
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        # Apply global average pooling
        x = self.avgpool(x)
        x = torch.flatten(x, 1)  # Flatten the output for the fully connected layer
        x = self.fc(x)  # Final output layer
        return x

# Define the transformation to normalize the images and convert them to tensors
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert image to PyTorch Tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images
])

# Load the CIFAR-10 dataset for training and testing with the above transformations
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)  # Load data in batches

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = DataLoader(testset, batch_size=64, shuffle=False)  # Load test data

import matplotlib.pyplot as plt
import numpy as np

# Function to display an image
def imshow(img):
    img = img / 2 + 0.5  # Unnormalize the image back to [0, 1] range
    npimg = img.numpy()  # Convert the tensor to a NumPy array for plotting
    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Rearrange the dimensions for visualization
    plt.show()

# Get a batch of images from the training set
dataiter = iter(trainloader)
images, labels = dataiter.next()

# Display the images in the batch
imshow(torchvision.utils.make_grid(images))

# Initialize the ResNet model with 10 output classes (CIFAR-10 has 10 classes)
model = ResNet(num_classes=10).cuda()

# Define the loss function (cross-entropy loss) for multi-class classification
criterion = nn.CrossEntropyLoss()

# Set up the optimizer (Adam optimizer with learning rate of 0.001)
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training the ResNet model for 10 epochs
num_epochs = 10

for epoch in range(num_epochs):
    model.train()  # Set the model to training mode
    running_loss = 0.0  # Track the loss for the current epoch

    # Iterate over the batches of training data
    for inputs, labels in trainloader:
        optimizer.zero_grad()  # Zero the gradients from the previous step

        # Forward pass: Compute the output of the model
        inputs = inputs.cuda()
        labels = labels.cuda()
        outputs = model(inputs)

        # Compute the loss
        loss = criterion(outputs, labels)

        # Backward pass: Compute the gradients
        loss.backward()

        # Update the model parameters
        optimizer.step()

        # Update the running loss
        running_loss += loss.item()

    # Print the loss for the current epoch
    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(trainloader)}")

# Evaluate the model on the test set
model.eval()  # Set the model to evaluation mode
correct = 0
total = 0

with torch.no_grad():  # Disable gradient calculation for evaluation
    for inputs, labels in testloader:
        inputs = inputs.cuda()
        labels = labels.cuda()
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)  # Get the predicted class
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

# Calculate the accuracy of the model on the test set
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")

